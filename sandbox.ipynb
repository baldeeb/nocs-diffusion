{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import argparse\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from utils.dataset import *\n",
    "from utils.misc import *\n",
    "from utils.data import *\n",
    "from models.vae_gaussian import *\n",
    "from models.vae_flow import *\n",
    "from models.flow import add_spectral_norm, spectral_norm_power_iteration\n",
    "from evaluation import *\n",
    "\n",
    "def normalize_point_clouds(pcs, mode, logger):\n",
    "    if mode is None:\n",
    "        logger.info('Will not normalize point clouds.')\n",
    "        return pcs\n",
    "    logger.info('Normalization mode: %s' % mode)\n",
    "    for i in tqdm(range(pcs.size(0)), desc='Normalize'):\n",
    "        pc = pcs[i]\n",
    "        if mode == 'shape_unit':\n",
    "            shift = pc.mean(dim=0).reshape(1, 3)\n",
    "            scale = pc.flatten().std().reshape(1, 1)\n",
    "        elif mode == 'shape_bbox':\n",
    "            pc_max, _ = pc.max(dim=0, keepdim=True) # (1, 3)\n",
    "            pc_min, _ = pc.min(dim=0, keepdim=True) # (1, 3)\n",
    "            shift = ((pc_min + pc_max) / 2).view(1, 3)\n",
    "            scale = (pc_max - pc_min).max().reshape(1, 1) / 2\n",
    "        pc = (pc - shift) / scale\n",
    "        pcs[i] = pc\n",
    "    return pcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-04-06 14:04:20,734::test::INFO] [ARGS::ckpt] './pretrained/GEN_chair.pt'\n",
      "[2023-04-06 14:04:20,734::test::INFO] [ARGS::ckpt] './pretrained/GEN_chair.pt'\n",
      "[2023-04-06 14:04:20,734::test::INFO] [ARGS::ckpt] './pretrained/GEN_chair.pt'\n",
      "[2023-04-06 14:04:20,734::test::INFO] [ARGS::ckpt] './pretrained/GEN_chair.pt'\n",
      "[2023-04-06 14:04:20,735::test::INFO] [ARGS::categories] ['chair']\n",
      "[2023-04-06 14:04:20,735::test::INFO] [ARGS::categories] ['chair']\n",
      "[2023-04-06 14:04:20,735::test::INFO] [ARGS::categories] ['chair']\n",
      "[2023-04-06 14:04:20,735::test::INFO] [ARGS::categories] ['chair']\n",
      "[2023-04-06 14:04:20,736::test::INFO] [ARGS::save_dir] './results'\n",
      "[2023-04-06 14:04:20,736::test::INFO] [ARGS::save_dir] './results'\n",
      "[2023-04-06 14:04:20,736::test::INFO] [ARGS::save_dir] './results'\n",
      "[2023-04-06 14:04:20,736::test::INFO] [ARGS::save_dir] './results'\n",
      "[2023-04-06 14:04:20,737::test::INFO] [ARGS::device] 'cuda'\n",
      "[2023-04-06 14:04:20,737::test::INFO] [ARGS::device] 'cuda'\n",
      "[2023-04-06 14:04:20,737::test::INFO] [ARGS::device] 'cuda'\n",
      "[2023-04-06 14:04:20,737::test::INFO] [ARGS::device] 'cuda'\n",
      "[2023-04-06 14:04:20,738::test::INFO] [ARGS::dataset_path] './data/shapenet.hdf5'\n",
      "[2023-04-06 14:04:20,738::test::INFO] [ARGS::dataset_path] './data/shapenet.hdf5'\n",
      "[2023-04-06 14:04:20,738::test::INFO] [ARGS::dataset_path] './data/shapenet.hdf5'\n",
      "[2023-04-06 14:04:20,738::test::INFO] [ARGS::dataset_path] './data/shapenet.hdf5'\n",
      "[2023-04-06 14:04:20,739::test::INFO] [ARGS::batch_size] 128\n",
      "[2023-04-06 14:04:20,739::test::INFO] [ARGS::batch_size] 128\n",
      "[2023-04-06 14:04:20,739::test::INFO] [ARGS::batch_size] 128\n",
      "[2023-04-06 14:04:20,739::test::INFO] [ARGS::batch_size] 128\n",
      "[2023-04-06 14:04:20,740::test::INFO] [ARGS::sample_num_points] 10240\n",
      "[2023-04-06 14:04:20,740::test::INFO] [ARGS::sample_num_points] 10240\n",
      "[2023-04-06 14:04:20,740::test::INFO] [ARGS::sample_num_points] 10240\n",
      "[2023-04-06 14:04:20,740::test::INFO] [ARGS::sample_num_points] 10240\n",
      "[2023-04-06 14:04:20,740::test::INFO] [ARGS::normalize] 'shape_bbox'\n",
      "[2023-04-06 14:04:20,740::test::INFO] [ARGS::normalize] 'shape_bbox'\n",
      "[2023-04-06 14:04:20,740::test::INFO] [ARGS::normalize] 'shape_bbox'\n",
      "[2023-04-06 14:04:20,740::test::INFO] [ARGS::normalize] 'shape_bbox'\n",
      "[2023-04-06 14:04:20,741::test::INFO] [ARGS::seed] 9988\n",
      "[2023-04-06 14:04:20,741::test::INFO] [ARGS::seed] 9988\n",
      "[2023-04-06 14:04:20,741::test::INFO] [ARGS::seed] 9988\n",
      "[2023-04-06 14:04:20,741::test::INFO] [ARGS::seed] 9988\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Arguments\n",
    "class Addict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Addict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self\n",
    "\n",
    "args = Addict({\n",
    "    \"ckpt\": \"./pretrained/GEN_chair.pt\",\n",
    "    \"categories\": [\"chair\"],\n",
    "    \"save_dir\": \"./results\",\n",
    "    \"device\": \"cuda\",\n",
    "    \"dataset_path\": \"./data/shapenet.hdf5\",\n",
    "    \"batch_size\": 128,\n",
    "    \"sample_num_points\": 5*2048,\n",
    "    \"normalize\": \"shape_bbox\",\n",
    "    \"seed\": 9988\n",
    "})\n",
    "\n",
    "# Logging\n",
    "save_dir = os.path.join(args.save_dir, 'GEN_Ours_%s_%d' % ('_'.join(args.categories), int(time.time())) )\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "logger = get_logger('test', save_dir)\n",
    "for k, v in vars(args).items():\n",
    "    logger.info('[ARGS::%s] %s' % (k, repr(v)))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-04-05 19:12:57,456::test::INFO] Loading datasets...\n",
      "[2023-04-05 19:12:57,456::test::INFO] Loading datasets...\n",
      "[2023-04-05 19:12:57,456::test::INFO] Loading datasets...\n",
      "[2023-04-05 19:12:57,538::test::INFO] Loading model...\n",
      "[2023-04-05 19:12:57,538::test::INFO] Loading model...\n",
      "[2023-04-05 19:12:57,538::test::INFO] Loading model...\n",
      "[2023-04-05 19:12:57,570::test::INFO] FlowVAE(\n",
      "  (encoder): PointNetEncoder(\n",
      "    (conv1): Conv1d(3, 128, kernel_size=(1,), stride=(1,))\n",
      "    (conv2): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
      "    (conv3): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
      "    (conv4): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc1_m): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (fc2_m): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (fc3_m): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (fc_bn1_m): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc_bn2_m): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc1_v): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (fc2_v): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (fc3_v): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (fc_bn1_v): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc_bn2_v): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (flow): SequentialFlow(\n",
      "    (chain): ModuleList(\n",
      "      (0-13): 14 x CouplingLayer(\n",
      "        (net_s_t): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (diffusion): DiffusionPoint(\n",
      "    (net): PointwiseNet(\n",
      "      (layers): ModuleList(\n",
      "        (0): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=3, out_features=128, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=128, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=128, bias=True)\n",
      "        )\n",
      "        (1): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=256, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=256, bias=True)\n",
      "        )\n",
      "        (2): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=256, out_features=512, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=512, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=512, bias=True)\n",
      "        )\n",
      "        (3): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=512, out_features=256, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=256, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=256, bias=True)\n",
      "        )\n",
      "        (4): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=256, out_features=128, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=128, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=128, bias=True)\n",
      "        )\n",
      "        (5): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=128, out_features=3, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=3, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=3, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (var_sched): VarianceSchedule()\n",
      "  )\n",
      ")\n",
      "[2023-04-05 19:12:57,570::test::INFO] FlowVAE(\n",
      "  (encoder): PointNetEncoder(\n",
      "    (conv1): Conv1d(3, 128, kernel_size=(1,), stride=(1,))\n",
      "    (conv2): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
      "    (conv3): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
      "    (conv4): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc1_m): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (fc2_m): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (fc3_m): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (fc_bn1_m): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc_bn2_m): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc1_v): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (fc2_v): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (fc3_v): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (fc_bn1_v): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc_bn2_v): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (flow): SequentialFlow(\n",
      "    (chain): ModuleList(\n",
      "      (0-13): 14 x CouplingLayer(\n",
      "        (net_s_t): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (diffusion): DiffusionPoint(\n",
      "    (net): PointwiseNet(\n",
      "      (layers): ModuleList(\n",
      "        (0): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=3, out_features=128, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=128, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=128, bias=True)\n",
      "        )\n",
      "        (1): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=256, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=256, bias=True)\n",
      "        )\n",
      "        (2): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=256, out_features=512, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=512, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=512, bias=True)\n",
      "        )\n",
      "        (3): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=512, out_features=256, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=256, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=256, bias=True)\n",
      "        )\n",
      "        (4): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=256, out_features=128, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=128, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=128, bias=True)\n",
      "        )\n",
      "        (5): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=128, out_features=3, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=3, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=3, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (var_sched): VarianceSchedule()\n",
      "  )\n",
      ")\n",
      "[2023-04-05 19:12:57,570::test::INFO] FlowVAE(\n",
      "  (encoder): PointNetEncoder(\n",
      "    (conv1): Conv1d(3, 128, kernel_size=(1,), stride=(1,))\n",
      "    (conv2): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
      "    (conv3): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
      "    (conv4): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc1_m): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (fc2_m): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (fc3_m): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (fc_bn1_m): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc_bn2_m): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc1_v): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (fc2_v): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (fc3_v): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (fc_bn1_v): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc_bn2_v): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (flow): SequentialFlow(\n",
      "    (chain): ModuleList(\n",
      "      (0-13): 14 x CouplingLayer(\n",
      "        (net_s_t): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (diffusion): DiffusionPoint(\n",
      "    (net): PointwiseNet(\n",
      "      (layers): ModuleList(\n",
      "        (0): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=3, out_features=128, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=128, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=128, bias=True)\n",
      "        )\n",
      "        (1): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=256, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=256, bias=True)\n",
      "        )\n",
      "        (2): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=256, out_features=512, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=512, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=512, bias=True)\n",
      "        )\n",
      "        (3): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=512, out_features=256, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=256, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=256, bias=True)\n",
      "        )\n",
      "        (4): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=256, out_features=128, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=128, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=128, bias=True)\n",
      "        )\n",
      "        (5): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=128, out_features=3, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=3, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=3, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (var_sched): VarianceSchedule()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d19bbb3606d14aeb841d6862792ad56a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m     36\u001b[0m         z \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn([args\u001b[39m.\u001b[39mbatch_size, ckpt[\u001b[39m'\u001b[39m\u001b[39margs\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mlatent_dim])\u001b[39m.\u001b[39mto(args\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m---> 37\u001b[0m         x \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49msample(z, args\u001b[39m.\u001b[39;49msample_num_points, flexibility\u001b[39m=\u001b[39;49mckpt[\u001b[39m'\u001b[39;49m\u001b[39margs\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mflexibility)\n\u001b[1;32m     38\u001b[0m         gen_pcs\u001b[39m.\u001b[39mappend(x\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu())\n\u001b[1;32m     39\u001b[0m gen_pcs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(gen_pcs, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)[:\u001b[39mlen\u001b[39m(test_dset)]\n",
      "File \u001b[0;32m~/Code/others/diffusion-point-cloud/models/vae_flow.py:70\u001b[0m, in \u001b[0;36mFlowVAE.sample\u001b[0;34m(self, w, num_points, flexibility, truncate_std)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39m# Reverse: z <- w.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m z \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflow(w, reverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mview(batch_size, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 70\u001b[0m samples \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdiffusion\u001b[39m.\u001b[39;49msample(num_points, context\u001b[39m=\u001b[39;49mz, flexibility\u001b[39m=\u001b[39;49mflexibility)\n\u001b[1;32m     71\u001b[0m \u001b[39mreturn\u001b[39;00m samples\n",
      "File \u001b[0;32m~/Code/others/diffusion-point-cloud/models/diffusion.py:139\u001b[0m, in \u001b[0;36mDiffusionPoint.sample\u001b[0;34m(self, num_points, context, point_dim, flexibility, ret_traj)\u001b[0m\n\u001b[1;32m    137\u001b[0m x_next \u001b[39m=\u001b[39m c0 \u001b[39m*\u001b[39m (x_t \u001b[39m-\u001b[39m c1 \u001b[39m*\u001b[39m e_theta) \u001b[39m+\u001b[39m sigma \u001b[39m*\u001b[39m z\n\u001b[1;32m    138\u001b[0m traj[t\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m x_next\u001b[39m.\u001b[39mdetach()     \u001b[39m# Stop gradient and save trajectory.\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m traj[t] \u001b[39m=\u001b[39m traj[t]\u001b[39m.\u001b[39;49mcpu()         \u001b[39m# Move previous output to CPU memory.\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ret_traj:\n\u001b[1;32m    141\u001b[0m     \u001b[39mdel\u001b[39;00m traj[t]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Checkpoint\n",
    "ckpt = torch.load(args.ckpt)\n",
    "seed_all(args.seed)\n",
    "\n",
    "# Datasets and loaders\n",
    "logger.info('Loading datasets...')\n",
    "test_dset = ShapeNetCore(\n",
    "    path=args.dataset_path,\n",
    "    cates=args.categories,\n",
    "    split='test',\n",
    "    scale_mode=args.normalize,\n",
    ")\n",
    "test_loader = DataLoader(test_dset, batch_size=args.batch_size, num_workers=0)\n",
    "\n",
    "# Model\n",
    "logger.info('Loading model...')\n",
    "if ckpt['args'].model == 'gaussian':\n",
    "    model = GaussianVAE(ckpt['args']).to(args.device)\n",
    "elif ckpt['args'].model == 'flow':\n",
    "    model = FlowVAE(ckpt['args']).to(args.device)\n",
    "logger.info(repr(model))\n",
    "# if ckpt['args'].spectral_norm:\n",
    "#     add_spectral_norm(model, logger=logger)\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "\n",
    "# Reference Point Clouds\n",
    "ref_pcs = []\n",
    "for i, data in enumerate(test_dset):\n",
    "    ref_pcs.append(data['pointcloud'].unsqueeze(0))\n",
    "ref_pcs = torch.cat(ref_pcs, dim=0)\n",
    "\n",
    "# Generate Point Clouds\n",
    "gen_pcs = []\n",
    "for i in tqdm(range(0, math.ceil(len(test_dset) / args.batch_size)), 'Generate'):\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn([args.batch_size, ckpt['args'].latent_dim]).to(args.device)\n",
    "        x = model.sample(z, args.sample_num_points, flexibility=ckpt['args'].flexibility)\n",
    "        gen_pcs.append(x.detach().cpu())\n",
    "gen_pcs = torch.cat(gen_pcs, dim=0)[:len(test_dset)]\n",
    "\n",
    "if args.normalize is not None:\n",
    "    gen_pcs = normalize_point_clouds(gen_pcs, mode=args.normalize, logger=logger)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Barebones Generation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-04-06 14:04:26,724::test::INFO] Loading model...\n",
      "[2023-04-06 14:04:26,724::test::INFO] Loading model...\n",
      "[2023-04-06 14:04:26,724::test::INFO] Loading model...\n",
      "[2023-04-06 14:04:26,724::test::INFO] Loading model...\n",
      "[2023-04-06 14:04:26,755::test::INFO] FlowVAE(\n",
      "  (encoder): PointNetEncoder(\n",
      "    (conv1): Conv1d(3, 128, kernel_size=(1,), stride=(1,))\n",
      "    (conv2): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
      "    (conv3): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
      "    (conv4): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc1_m): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (fc2_m): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (fc3_m): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (fc_bn1_m): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc_bn2_m): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc1_v): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (fc2_v): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (fc3_v): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (fc_bn1_v): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc_bn2_v): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (flow): SequentialFlow(\n",
      "    (chain): ModuleList(\n",
      "      (0-13): 14 x CouplingLayer(\n",
      "        (net_s_t): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (diffusion): DiffusionPoint(\n",
      "    (net): PointwiseNet(\n",
      "      (layers): ModuleList(\n",
      "        (0): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=3, out_features=128, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=128, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=128, bias=True)\n",
      "        )\n",
      "        (1): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=256, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=256, bias=True)\n",
      "        )\n",
      "        (2): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=256, out_features=512, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=512, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=512, bias=True)\n",
      "        )\n",
      "        (3): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=512, out_features=256, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=256, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=256, bias=True)\n",
      "        )\n",
      "        (4): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=256, out_features=128, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=128, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=128, bias=True)\n",
      "        )\n",
      "        (5): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=128, out_features=3, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=3, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=3, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (var_sched): VarianceSchedule()\n",
      "  )\n",
      ")\n",
      "[2023-04-06 14:04:26,755::test::INFO] FlowVAE(\n",
      "  (encoder): PointNetEncoder(\n",
      "    (conv1): Conv1d(3, 128, kernel_size=(1,), stride=(1,))\n",
      "    (conv2): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
      "    (conv3): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
      "    (conv4): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc1_m): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (fc2_m): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (fc3_m): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (fc_bn1_m): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc_bn2_m): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc1_v): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (fc2_v): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (fc3_v): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (fc_bn1_v): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc_bn2_v): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (flow): SequentialFlow(\n",
      "    (chain): ModuleList(\n",
      "      (0-13): 14 x CouplingLayer(\n",
      "        (net_s_t): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (diffusion): DiffusionPoint(\n",
      "    (net): PointwiseNet(\n",
      "      (layers): ModuleList(\n",
      "        (0): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=3, out_features=128, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=128, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=128, bias=True)\n",
      "        )\n",
      "        (1): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=256, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=256, bias=True)\n",
      "        )\n",
      "        (2): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=256, out_features=512, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=512, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=512, bias=True)\n",
      "        )\n",
      "        (3): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=512, out_features=256, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=256, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=256, bias=True)\n",
      "        )\n",
      "        (4): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=256, out_features=128, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=128, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=128, bias=True)\n",
      "        )\n",
      "        (5): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=128, out_features=3, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=3, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=3, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (var_sched): VarianceSchedule()\n",
      "  )\n",
      ")\n",
      "[2023-04-06 14:04:26,755::test::INFO] FlowVAE(\n",
      "  (encoder): PointNetEncoder(\n",
      "    (conv1): Conv1d(3, 128, kernel_size=(1,), stride=(1,))\n",
      "    (conv2): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
      "    (conv3): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
      "    (conv4): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc1_m): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (fc2_m): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (fc3_m): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (fc_bn1_m): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc_bn2_m): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc1_v): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (fc2_v): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (fc3_v): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (fc_bn1_v): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc_bn2_v): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (flow): SequentialFlow(\n",
      "    (chain): ModuleList(\n",
      "      (0-13): 14 x CouplingLayer(\n",
      "        (net_s_t): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (diffusion): DiffusionPoint(\n",
      "    (net): PointwiseNet(\n",
      "      (layers): ModuleList(\n",
      "        (0): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=3, out_features=128, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=128, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=128, bias=True)\n",
      "        )\n",
      "        (1): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=256, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=256, bias=True)\n",
      "        )\n",
      "        (2): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=256, out_features=512, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=512, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=512, bias=True)\n",
      "        )\n",
      "        (3): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=512, out_features=256, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=256, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=256, bias=True)\n",
      "        )\n",
      "        (4): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=256, out_features=128, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=128, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=128, bias=True)\n",
      "        )\n",
      "        (5): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=128, out_features=3, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=3, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=3, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (var_sched): VarianceSchedule()\n",
      "  )\n",
      ")\n",
      "[2023-04-06 14:04:26,755::test::INFO] FlowVAE(\n",
      "  (encoder): PointNetEncoder(\n",
      "    (conv1): Conv1d(3, 128, kernel_size=(1,), stride=(1,))\n",
      "    (conv2): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
      "    (conv3): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
      "    (conv4): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc1_m): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (fc2_m): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (fc3_m): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (fc_bn1_m): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc_bn2_m): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc1_v): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (fc2_v): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (fc3_v): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (fc_bn1_v): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc_bn2_v): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (flow): SequentialFlow(\n",
      "    (chain): ModuleList(\n",
      "      (0-13): 14 x CouplingLayer(\n",
      "        (net_s_t): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (diffusion): DiffusionPoint(\n",
      "    (net): PointwiseNet(\n",
      "      (layers): ModuleList(\n",
      "        (0): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=3, out_features=128, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=128, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=128, bias=True)\n",
      "        )\n",
      "        (1): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=128, out_features=256, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=256, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=256, bias=True)\n",
      "        )\n",
      "        (2): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=256, out_features=512, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=512, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=512, bias=True)\n",
      "        )\n",
      "        (3): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=512, out_features=256, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=256, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=256, bias=True)\n",
      "        )\n",
      "        (4): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=256, out_features=128, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=128, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=128, bias=True)\n",
      "        )\n",
      "        (5): ConcatSquashLinear(\n",
      "          (_layer): Linear(in_features=128, out_features=3, bias=True)\n",
      "          (_hyper_bias): Linear(in_features=259, out_features=3, bias=False)\n",
      "          (_hyper_gate): Linear(in_features=259, out_features=3, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (var_sched): VarianceSchedule()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checkpoint\n",
    "ckpt = torch.load(args.ckpt)\n",
    "seed_all(args.seed)\n",
    "\n",
    "# Model\n",
    "logger.info('Loading model...')\n",
    "if ckpt['args'].model == 'gaussian':\n",
    "    model = GaussianVAE(ckpt['args']).to(args.device)\n",
    "elif ckpt['args'].model == 'flow':\n",
    "    model = FlowVAE(ckpt['args']).to(args.device)\n",
    "logger.info(repr(model))\n",
    "# if ckpt['args'].spectral_norm:\n",
    "#     add_spectral_norm(model, logger=logger)\n",
    "model.load_state_dict(ckpt['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-04-06 14:04:27,770::test::INFO] Normalization mode: shape_bbox\n",
      "[2023-04-06 14:04:27,770::test::INFO] Normalization mode: shape_bbox\n",
      "[2023-04-06 14:04:27,770::test::INFO] Normalization mode: shape_bbox\n",
      "[2023-04-06 14:04:27,770::test::INFO] Normalization mode: shape_bbox\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b69db3fe37584e4fa453be086da10297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Normalize:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate Point Clouds\n",
    "gen_pcs = []\n",
    "with torch.no_grad():\n",
    "    z = torch.randn([3, ckpt['args'].latent_dim]).to(args.device)\n",
    "    x = model.sample(z, args.sample_num_points, flexibility=ckpt['args'].flexibility)\n",
    "    gen_pcs.append(x.detach().cpu())\n",
    "gen_pcs = torch.cat(gen_pcs, dim=0)\n",
    "\n",
    "if args.normalize is not None:\n",
    "    gen_pcs = normalize_point_clouds(gen_pcs, mode=args.normalize, logger=logger)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Broken Down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-04-06 14:39:38,490::test::INFO] Normalization mode: shape_bbox\n",
      "[2023-04-06 14:39:38,490::test::INFO] Normalization mode: shape_bbox\n",
      "[2023-04-06 14:39:38,490::test::INFO] Normalization mode: shape_bbox\n",
      "[2023-04-06 14:39:38,490::test::INFO] Normalization mode: shape_bbox\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "756baba5b39946ccbd6761c3a775dabf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Normalize:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen_pcs = []\n",
    "samples = []\n",
    "with torch.no_grad():\n",
    "    # z = torch.randn([1, ckpt['args'].latent_dim]).to(args.device)\n",
    "    # x = model.sample(z, args.sample_num_points, flexibility=ckpt['args'].flexibility)\n",
    "    \n",
    "    x_T = x\n",
    "    # x_T = torch.randn([z.size(0), args.sample_num_points, 3]).to(args.device)\n",
    "    # x_T[x_T[:, :, 0]>0] *= -1\n",
    "    # x_T[:, :, 0] += 3\n",
    "    \n",
    "    x = model.diffusion.sample_this(x_T, context=z, flexibility=ckpt['args'].flexibility)\n",
    "\n",
    "    gen_pcs.append(x.detach().cpu())\n",
    "    samples.append(x_T.detach().cpu())\n",
    "gen_pcs = torch.cat(gen_pcs, dim=0)\n",
    "samples = torch.cat(samples, dim=0)\n",
    "\n",
    "if args.normalize is not None:\n",
    "    gen_pcs = normalize_point_clouds(gen_pcs, mode=args.normalize, logger=logger)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8604, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes3D: >"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "# Plot 3D Point Cloud using matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "\n",
    "def plot_3d_point_cloud(x, y, z, ax=None, title='', elev=10, azim=240, axis_off=False):\n",
    "    def _to_np(v):\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            v = v.clone().detach().cpu().numpy()\n",
    "        return v\n",
    "    x, y, z = _to_np(x), _to_np(y), _to_np(z)\n",
    "    if ax is None:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.view_init(elev=elev, azim=azim)\n",
    "    if axis_off: ax.axis('off')\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    ax.scatter(x, y, z, s=0.5, c=x/10)\n",
    "    return ax\n",
    "\n",
    "print(samples[0].shape)\n",
    "i = 0\n",
    "\n",
    "plot_3d_point_cloud(samples[i, :, 0], samples[i, :, 1], samples[i, :, 2]) # x, y, z\n",
    "plot_3d_point_cloud(gen_pcs[i, :, 0], gen_pcs[i, :, 1], gen_pcs[i, :, 2]) # x, y, z"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data manipulation\n",
    "\n",
    "Below I mess around with data to run experiments on the diffusion process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "xnew = [x0[x0[:, 0]> 0] for x0 in x]\n",
    "num_pts = min([n.shape[0] for n in xnew])\n",
    "xnew = torch.stack([n[:num_pts] for n in xnew])\n",
    "\n",
    "# Add noise\n",
    "xnew = xnew + torch.randn(xnew.shape).to(xnew.device) * 0.05\n",
    "\n",
    "plot_3d_point_cloud(xnew[i, :, 0], xnew[i, :, 1], xnew[i, :, 2], title='Noisy partial points') # x, y, z\n",
    "\n",
    "x = xnew"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save\n",
    "logger.info('Saving point clouds...')\n",
    "np.save(os.path.join(save_dir, 'out.npy'), gen_pcs.numpy())\n",
    "\n",
    "# Compute metrics\n",
    "with torch.no_grad():\n",
    "    results = compute_all_metrics(gen_pcs.to(args.device), ref_pcs.to(args.device), args.batch_size)\n",
    "    results = {k:v.item() for k, v in results.items()}\n",
    "    jsd = jsd_between_point_cloud_sets(gen_pcs.cpu().numpy(), ref_pcs.cpu().numpy())\n",
    "    results['jsd'] = jsd\n",
    "\n",
    "for k, v in results.items():\n",
    "    logger.info('%s: %.12f' % (k, v))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shapo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
