defaults:
  - _self_
  # - .@context_model.model: pcd_encoder # pcd_encoder, cloud_encoder, mask_diffuser

_target_: nocs_diffusion.models.PointContextualized2dDiffusionModel
diffusion_model:
  _target_:             diffusers.UNet2DConditionModel
  sample_size:          cfg['image_size']
  in_channels:          3
  out_channels:         3
  layers_per_block:     1
  block_out_channels:   [128, 128, 128] # the number of output channels for each UNet block  
  down_block_types:     ["CrossAttnDownBlock2D", "CrossAttnDownBlock2D", "CrossAttnDownBlock2D"] # regular ResNet downsampling block
  up_block_types:       ["CrossAttnUpBlock2D", "CrossAttnUpBlock2D", "CrossAttnUpBlock2D"]
  # up_block_types:       ["UpBlock2D", "UpBlock2D", "UpBlock2D"] # regular ResNet upsampling block
  cross_attention_dim:  256

context_model:
  _target_:  nocs_diffusion.models.load_model
  model:
    _target_: nocs_diffusion.models.blocks.PointNetEncoder 
    dims: [3, 32, 64, 128, 256]
  # When path is set, training starts from pre-trained context encoder. 
  path: # Expected to be set to train nocs_diffuser

# Source Doc: https://huggingface.co/docs/diffusers/en/api/schedulers/ddpm
scheduler: 
  _target_: diffusers.DDIMScheduler
  num_train_timesteps: 300
