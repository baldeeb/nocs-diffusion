defaults:
  - _self_
  - .@context_model.model: cloud_encoder

_target_: nocs_diffusion.models.PointContextualized2dDiffusionModel
diffusion_model:
  _target_:             diffusers.UNet2DConditionModel
  sample_size:          cfg['image_size']
  in_channels:          3
  out_channels:         3
  layers_per_block:     1
  block_out_channels:   [128, 128, 128] # the number of output channels for each UNet block  
  down_block_types:     ["CrossAttnDownBlock2D", "CrossAttnDownBlock2D", "CrossAttnDownBlock2D"] # regular ResNet downsampling block
  up_block_types:       ["UpBlock2D", "UpBlock2D", "UpBlock2D"] # regular ResNet upsampling block
  cross_attention_dim:  1028

context_model:
  _target_:  nocs_diffusion.models.load_model
  # model: # Model loaded in defaults
  # When path is set, training starts from pre-trained context encoder. 
  path: # Expected to be set to train nocs_diffuser

# Source Doc: https://huggingface.co/docs/diffusers/en/api/schedulers/ddpm
scheduler: 
  _target_: diffusers.DDPMScheduler
  num_train_timesteps: 300
